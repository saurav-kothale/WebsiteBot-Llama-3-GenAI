{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOJTJP0P6bv+Y4O6BRWTnPx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saurav-kothale/WebsiteBot-Llama-3-GenAI/blob/main/Website_bot_using_GenAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_a7CS07hxoIE",
        "outputId": "5f07cf4a-64e5-4d89-84bc-3df6248369f8",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pinecone in /usr/local/lib/python3.10/dist-packages (5.3.1)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone) (2024.8.30)\n",
            "Requirement already satisfied: pinecone-plugin-inference<2.0.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from pinecone) (1.1.0)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from pinecone) (0.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from pinecone) (2.8.2)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone) (4.12.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pinecone) (2.0.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.5.3->pinecone) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip -q install langchain\n",
        "!pip -q install bitsandbytes accelerate transformers\n",
        "!pip -q install sentence_transformers\n",
        "!pip -q install unstructured\n",
        "!pip install pinecone"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pinecone import Pinecone, ServerlessSpec\n",
        "from google.colab import userdata\n",
        "\n",
        "pc = Pinecone(api_key=userdata.get('pinecone_key'))\n"
      ],
      "metadata": {
        "id": "tz4w_S0Tx7RF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U langchain-community"
      ],
      "metadata": {
        "id": "EgCUya3CyShz",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import UnstructuredURLLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import Pinecone as PineconeStore\n",
        "import pinecone"
      ],
      "metadata": {
        "id": "u9uPrUE2yjMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, LlamaTokenizer, LlamaForCausalLM\n",
        "import transformers\n",
        "from langchain import HuggingFacePipeline\n",
        "from huggingface_hub import notebook_login\n",
        "import torch"
      ],
      "metadata": {
        "id": "fuz0fluvynhY",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy\n",
        "!pip install python-magic\n",
        "!pip install --upgrade nltk"
      ],
      "metadata": {
        "id": "_Ep1_JGEypGq",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Urls = [\"https://ineuron.ai/\"]\n",
        "\n",
        "loader = UnstructuredURLLoader(urls = Urls)\n",
        "data = loader.load()\n",
        "\n",
        "data"
      ],
      "metadata": {
        "id": "qTDS-zHwyrqa",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter=CharacterTextSplitter(\n",
        "    separator=\"\\n\",\n",
        "    chunk_size = 1000,\n",
        "    chunk_overlap = 200\n",
        ")"
      ],
      "metadata": {
        "id": "n6sbRfNhy-2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_chunks = text_splitter.split_documents(data)"
      ],
      "metadata": {
        "id": "FghBSXHVy-7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(text_chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAQWAz0uzEAi",
        "outputId": "94e619f6-34b6-4112-ed35-a2c53f195ccd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_chunks[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEFerYrAy--K",
        "outputId": "6ca9199a-98d4-4441-c3c2-1071a02a72b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'source': 'https://ineuron.ai/'}, page_content='Learning with iNeuron made\\nTake your career to the next level with industry ready programs, An entire learning ecosystem at your fingertips to make learning fun. Choose from a range of tech programs and make your next big career switch.\\n55%\\nAverage Salary Hike\\n400+\\nDifferent Courses\\n10000+\\nCareer Transitions\\n400+\\nHiring Partners\\nLIVE NOW\\nSupport System\\nOur support system is live again, this time it is bigger, better and faster. Experience a tech community like never seen before\\nOur Courses\\nSuccess Stories\\nFresher\\nAbhisekh Bhuyan\\nMLOps engineer\\nI got job as an MLOps engineer at synapsica at 13 LPA PPO because of \"End to End projects MLOps\" from iNeuron.\\nFrom\\nFresher\\nTo\\n79% Increment\\nSubham Kanungo\\nAssociate Data Scientist\\nI just joined EY as data analyst. It would not be possible with the support of Krish sir and Sudhanshu sir.\\nFrom\\nTo\\n100% Increment\\nSayan Saha\\nSoftware Engineer - Python')"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')"
      ],
      "metadata": {
        "id": "OLeGsblZy_Ap",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_result = embeddings.embed_query(\"Hello World\")\n",
        "len(query_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzT5swJZzNui",
        "outputId": "0646e2cc-0044-4561-99d2-6d641df2c432"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "384"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_name = \"website-bot\"\n",
        "\n",
        "pc.create_index(\n",
        "    name = index_name,\n",
        "    dimension=384, # Replace with your model dimensions\n",
        "    metric=\"cosine\", # Replace with your model metric\n",
        "    spec=ServerlessSpec(\n",
        "        cloud=\"aws\",\n",
        "        region=\"us-east-1\"\n",
        "  )\n",
        ")\n",
        "\n",
        "index = pc.Index(index_name)"
      ],
      "metadata": {
        "id": "gHKsfLQJy_DK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_name = \"website-bot\"\n",
        "index = pc.Index(index_name)"
      ],
      "metadata": {
        "id": "QvqtxztDy_FR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade langchain-pinecone\n",
        "!pip install langchain-pinecone"
      ],
      "metadata": {
        "collapsed": true,
        "id": "wJxBq1t2y_Hh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_pinecone import PineconeVectorStore\n",
        "\n",
        "vector_store = PineconeVectorStore(index=index, embedding=embeddings)"
      ],
      "metadata": {
        "id": "UM5Uy4ZOzjvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_store.add_documents(documents=text_chunks)"
      ],
      "metadata": {
        "id": "8AyY43lZzjxj",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "notebook_login()"
      ],
      "metadata": {
        "id": "9y6mx4_qzsxU",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -qq install langchain Groq langchain_core langchain_groq streamlit"
      ],
      "metadata": {
        "collapsed": true,
        "id": "pmVHS9DezszZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain.prompts import PromptTemplate\n",
        "# from langchain.chains import LLMChain\n",
        "\n",
        "# prompt_template = PromptTemplate(\n",
        "#     input_variables=[\"course_name\"],\n",
        "#     template=\"What is the price of the {course_name} course?\"\n",
        "# )"
      ],
      "metadata": {
        "id": "dHM3snNbHSie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = transformers.pipeline(\"text-generation\",\n",
        "                model=model,\n",
        "                tokenizer= tokenizer,\n",
        "                temperature=0.8,\n",
        "                top_p=0.95,\n",
        "                repetition_penalty=1.2,\n",
        "                torch_dtype=torch.bfloat16,\n",
        "                device_map=\"auto\",\n",
        "                max_new_tokens = 512,\n",
        "                do_sample=True,\n",
        "                top_k=30,\n",
        "                num_return_sequences=1,\n",
        "                eos_token_id=tokenizer.eos_token_id\n",
        "                )"
      ],
      "metadata": {
        "id": "G01CDhs5z2LC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm=HuggingFacePipeline(pipeline=pipe)"
      ],
      "metadata": {
        "id": "3RgFd_Jd0urq",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# llm_chain = LLMChain(llm = llm, prompt = prompt_template)"
      ],
      "metadata": {
        "id": "zzpTbieuHgyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# course_name = \"Full Stack Data Analytics\"\n",
        "# response = llm_chain.run(course_name)"
      ],
      "metadata": {
        "id": "ffzUEwB3HyQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm.predict(\"Please provide a concise summary of the Book Harry Potter\")"
      ],
      "metadata": {
        "id": "SKrwXM9X07kC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate\n",
        "\n",
        "prompt_template = \"\"\"\n",
        "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
        "You are a precise and accurate AI assistant. Your task is to answer the given question based solely on the provided context. If the information is not present in the context, respond with \"The provided context does not contain any information about this topic.\"\n",
        "<|eot_id|>\n",
        "<|start_header_id|>user<|end_header_id|>\n",
        "Context: {context}\n",
        "Question: {query}\n",
        "<|eot_id|>\n",
        "<|start_header_id|>assistant<|end_header_id|>\n",
        "\"\"\"\n",
        "\n",
        "# Initialize the LangChain PromptTemplate\n",
        "template = PromptTemplate(\n",
        "    input_variables=[\"query\"],\n",
        "    template=prompt_template,\n",
        ")"
      ],
      "metadata": {
        "id": "BQm0jJLwflAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade langchain"
      ],
      "metadata": {
        "id": "nlVwk_CHflIv",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain_core.output_parsers import StrOutputParser"
      ],
      "metadata": {
        "id": "BkFGdim11Hz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"map_reduce\", retriever=vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3}, chain_type_kwargs = {\"prompt\": template,\"output_parser\": StrOutputParser()}))"
      ],
      "metadata": {
        "id": "C_FuB_kS1S5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Is INeuron has hiring partners?\""
      ],
      "metadata": {
        "id": "9VOG4kOz1WGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = qa({\"query\": query})"
      ],
      "metadata": {
        "id": "QpAoDGtfrBmi",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer = result['result']\n",
        "print(answer)"
      ],
      "metadata": {
        "id": "8ap3vWeJrByi",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def post_process_answer(answer):\n",
        "    # Remove any text after \"FINAL ANSWER:\" if present\n",
        "    if \"FINAL ANSWER:\" in answer:\n",
        "        answer = answer.split(\"FINAL ANSWER:\")[1].strip()\n",
        "\n",
        "    # Remove any remaining instructions or prefixes\n",
        "    answer = answer.replace(\"Answer:\", \"\").strip()\n",
        "\n",
        "    return answer\n",
        "\n",
        "# When using the QA system\n",
        "query = \"Is INeuron has hiring partners?\"\n",
        "result = qa.run(query)\n",
        "processed_answer = post_process_answer(result)\n",
        "print(processed_answer)"
      ],
      "metadata": {
        "id": "-xoC0G7F0-wq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0d4720d-fbf4-451d-fc90-e4a0da1a043d",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This Agreement is governed by English law.\n",
            "\n",
            "QUESTION: What did the president say about Michael Jackson?\n",
            "=========\n",
            "Content: Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and the Cabinet. Justices of the Supreme Court. My fellow Americans.  \n",
            "\n",
            "Last year COVID-19 kept us apart. This year we are finally together again. \n",
            "\n",
            "Tonight, we meet as Democrats Republicans and Independents. But most importantly as Americans. \n",
            "\n",
            "With a duty to one another to the American people to the Constitution. \n",
            "\n",
            "And with an unwavering resolve that freedom will always triumph over tyranny. \n",
            "\n",
            "Six days ago, Russia’s Vladimir Putin sought to shake the foundations of the free world thinking he could make it bend to his menacing ways. But he badly miscalculated. \n",
            "\n",
            "He thought he could roll into Ukraine and the world would roll over. Instead he met a wall of strength he never imagined. \n",
            "\n",
            "He met the Ukrainian people. \n",
            "\n",
            "From President Zelenskyy to every Ukrainian, their fearlessness, their courage, their determination, inspires the world. \n",
            "\n",
            "Groups of citizens blocking tanks with their bodies. Everyone from students to retirees teachers turned soldiers defending their homeland.\n",
            "\n",
            "Content: And we won’t stop. \n",
            "\n",
            "We have lost so much to COVID-19. Time with one another. And worst of all, so much loss of life. \n",
            "\n",
            "Let’s use this moment to reset. Let’s stop looking at COVID-19 as a partisan dividing line and see it for what it is: A God-awful disease.  \n",
            "\n",
            "Let’s stop seeing each other as enemies, and start seeing each other for who we really are: Fellow Americans.  \n",
            "\n",
            "We can’t change how divided we’ve been. But we can change how we move forward—on COVID-19 and other issues we must face together. \n",
            "\n",
            "I recently visited the New York City Police Department days after the funerals of Officer Wilbert Mora and his partner, Officer Jason Rivera. \n",
            "\n",
            "They were responding to a 9-1-1 call when a man shot and killed them with a stolen gun. \n",
            "\n",
            "Officer Mora was 27 years old. \n",
            "\n",
            "Officer Rivera was 22. \n",
            "\n",
            "Both Dominican Americans who’d grown up on the same streets they later chose to patrol as police officers. \n",
            "\n",
            "I spoke with their families and told them that we are forever in debt for their sacrifice, and we will carry on their mission to restore the trust and safety every community deserves.\n",
            "\n",
            "Content: And a proud Ukrainian people, who have known 30 years  of independence, have repeatedly shown that they will not tolerate anyone who tries to take their country backwards.  \n",
            "\n",
            "To all Americans, I will be honest with you, as I’ve always promised. A Russian dictator, invading a foreign country, has costs around the world. \n",
            "\n",
            "And I’m taking robust action to make sure the pain of our sanctions  is targeted at Russia’s economy. And I will use every tool at our disposal to protect American businesses and consumers. \n",
            "\n",
            "Tonight, I can announce that the United States has worked with 30 other countries to release 60 Million barrels of oil from reserves around the world.  \n",
            "\n",
            "America will lead that effort, releasing 30 Million barrels from our own Strategic Petroleum Reserve. And we stand ready to do more if necessary, unified with our allies.  \n",
            "\n",
            "These steps will help blunt gas prices here at home. And I know the news about what’s happening can seem alarming. \n",
            "\n",
            "But I want you to know that we are going to be okay.\n",
            "\n",
            "Content: More support for patients and families. \n",
            "\n",
            "To get there, I call on Congress to fund ARPA-H, the Advanced Research Projects Agency for Health. \n",
            "\n",
            "It’s based on DARPA—the Defense Department project that led to the Internet, GPS, and so much more.  \n",
            "\n",
            "ARPA-H will have a singular purpose—to drive breakthroughs in cancer, Alzheimer’s, diabetes, and more. \n",
            "\n",
            "A unity agenda for the nation. \n",
            "\n",
            "We can do this. \n",
            "\n",
            "My fellow Americans—tonight , we have gathered in a sacred space—the citadel of our democracy. \n",
            "\n",
            "In this Capitol, generation after generation, Americans have debated great questions amid great strife, and have done great things. \n",
            "\n",
            "We have fought for freedom, expanded liberty, defeated totalitarianism and terror. \n",
            "\n",
            "And built the strongest, freest, and most prosperous nation the world has ever known. \n",
            "\n",
            "Now is the hour. \n",
            "\n",
            "Our moment of responsibility. \n",
            "\n",
            "Our test of resolve and conscience, of history itself. \n",
            "\n",
            "It is in this moment that our character is formed. Our purpose is found. Our future is forged. \n",
            "\n",
            "Well I know this nation.\n",
            "=========\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u8tLCeiz8808"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}